{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5cb0b437036b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 读取图像\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimg1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'image1.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mimg2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'image2.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "# 读取待拼接图像\n",
    "MIN = 10\n",
    "img1 = cv.imread('1.jpg')\n",
    "img2 = cv.imread('2.jpg')\n",
    "# 统一图像大小\n",
    "height1 = int(img1.shape[0])\n",
    "width1 = int(img1.shape[1])\n",
    "dim = (width1, height1)\n",
    "img2 = cv.resize(img2, dim, interpolation=cv.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建SIFT特征点检测\n",
    "sift = cv.SIFT_create()\n",
    " \n",
    "# 检测兴趣点并计算描述子\n",
    "kp1, describe1 = sift.detectAndCompute(img1, None)\n",
    "kp2, describe2 = sift.detectAndCompute(img2, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用OpenCV中的FLANN匹配算法进行特征匹配，并返回最近邻和次近邻匹配的结果\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "indexParams = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "searchParams = dict(checks=50)\n",
    "flann = cv.FlannBasedMatcher(indexParams,searchParams)\n",
    "matches = flann.knnMatch(describe1, describe2, k=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 储存特征匹配最好的优质匹配点对\n",
    "'''基于距离阈值选择优质匹配点对，如果最近邻m的距离小于0.65倍的次近邻n的距离，\n",
    "则认为这个匹配点对是优质的，将它存储在good列表中。'''\n",
    "good = []\n",
    "for m,n in matches:\n",
    "    if m.distance < 0.65 * n.distance:\n",
    "        good.append(m)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化特征匹配结果,并保存\n",
    "pic3 = cv.drawMatches(img1=img1, keypoints1=kp1, img2=img2, keypoints2=kp2, matches1to2=good, outImg=None)\n",
    "cv.imwrite('pic3.jpg', pic3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RANSAC算法计算单应性矩阵\n",
    "\n",
    "src_pts = np.float32([kp1[m.queryIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "tge_pts = np.float32([kp2[m.trainIdx].pt for m in good]).reshape(-1, 1, 2)\n",
    "M, mask = cv.findHomography(src_pts, tge_pts, cv.RANSAC, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 源图像img2图像扭曲（透视变换）\n",
    "warpimg = cv.warpPerspective(img2, np.linalg.inv(M), (img1.shape[1] + img2.shape[1], img2.shape[0]))\n",
    "cv.imwrite('warpimg1.jpg',warpimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 拼接图像,去除黑边\n",
    "direct = warpimg.copy()\n",
    "direct[0:img1.shape[0], 0:img1.shape[1]] = img1\n",
    "rows, cols = img1.shape[:2]\n",
    "gray = cv.cvtColor(direct, cv.COLOR_BGR2GRAY)\n",
    "_, thresh = cv.threshold(gray, 1, 255, cv.THRESH_BINARY)\n",
    "contours, _ = cv.findContours(thresh, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "x, y, w, h = cv.boundingRect(contours[0])\n",
    "direct = direct[y:y+h, x:x+w]\n",
    "\n",
    "cv.imwrite('result.jpg',direct)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
