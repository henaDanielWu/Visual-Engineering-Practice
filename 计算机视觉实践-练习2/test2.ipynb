{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.nn as nn\n",
    "import mindspore.ops as ops\n",
    "from download import download\n",
    "import mindspore\n",
    "from mindspore.dataset import MnistDataset\n",
    "from mindspore.dataset import transforms\n",
    "from mindspore.dataset import vision\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Cell):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.maxpool2 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Dense(16*8*8, 120)\n",
    "        self.fc2 = nn.Dense(120, 84)\n",
    "        self.fc3 = nn.Dense(84, 10)\n",
    " \n",
    "    def construct(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = x.reshape((-1, 16*8*8))\n",
    "        x = ops.relu(self.fc1(x))\n",
    "        x = ops.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        output = ops.log_softmax(x, axis=1)\n",
    "        return output\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义训练过程  \n",
    "def train_runner(model,  trainloader, optimizer, epoch):\n",
    "    #训练模型, 启用 BatchNormalization 和 Dropout, 将BatchNormalization和Dropout置为True\n",
    "    \n",
    "    total = 0\n",
    "    correct =0.0\n",
    "    \n",
    "    #enumerate迭代已加载的数据集,同时获取数据和数据下标\n",
    "    for i, (inputs,labels) in enumerate(trainloader.create_tuple_iterator()):\n",
    "        \n",
    "        #保存训练结果\n",
    "        (loss,outputs),grad = model(inputs,labels)\n",
    "        \n",
    "        #获取最大概率的预测结果\n",
    "        #dim=1表示返回每一行的最大值对应的列下标\n",
    "        predict = outputs.argmax(axis=1)\n",
    "        total += labels.shape[0]\n",
    "        correct += (predict == labels).sum().item()\n",
    "        #反向传播\n",
    "        optimizer(grad)\n",
    "        if i % 1000 == 0:\n",
    "            #loss.item()表示当前loss的数值\n",
    "            print(\"Train Epoch{} \\t Loss: {:.6f}, accuracy: {:.6f}%\".format(epoch, loss.item(), 100*(correct/total)))\n",
    "            Loss.append(loss.item())\n",
    "            Accuracy.append(correct/total)\n",
    "    return loss.item(), correct/total\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义测试过程\n",
    "def test_runner(model,  testloader):\n",
    "    #设置成测试模式\n",
    "    model.set_train(False)\n",
    "    #统计模型正确率, 设置初始值\n",
    "    correct = 0.0\n",
    "    test_loss = 0.0\n",
    "    total = 0\n",
    "    \n",
    "    for (data, label) in testloader.create_tuple_iterator():\n",
    "        output = model(data)\n",
    "        test_loss += ops.cross_entropy(output, label).item()\n",
    "        predict = output.argmax(axis=1)\n",
    "        #计算正确数量\n",
    "        total += label.shape[0]\n",
    "        correct += (predict == label).sum().item()\n",
    "    #计算损失值\n",
    "    print(\"test_avarage_loss: {:.6f}, accuracy: {:.6f}%\".format(test_loss/total, 100*(correct/total)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#利用训练好的模型进行数字识别\n",
    "def test_model(path):\n",
    "    param_dict = mindspore.load_checkpoint( './models/mnist.ckpt') #加载模型\n",
    "    model=LeNet()\n",
    "    mindspore.load_param_into_net(model, param_dict)\n",
    "    model.set_train(False)    #把模型转为test模式\n",
    "    \n",
    "    #读取要预测的图片\n",
    "    img = cv2.imread(\"./img/image.png\")\n",
    "    img=cv2.resize(img,dsize=(32,32),interpolation=cv2.INTER_NEAREST)\n",
    "    cv2.imwrite('./img/resize.jpg',img) # 显示图片\n",
    "    \n",
    "    \n",
    "    # 导入图片，图片扩展后为[1，1，32，32]\n",
    "    trans = transforms.Compose(\n",
    "        [   \n",
    "            vision.ToTensor(),\n",
    "            vision.Normalize((0.1307,), (0.3081,),is_hwc=False),\n",
    "            \n",
    "        ])\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)#图片转为灰度图，因为mnist数据集都是灰度图\n",
    "    cv2.imwrite('./img/trans.jpg',img) # 显示图片\n",
    "    img = trans(img)\n",
    "    img=mindspore.tensor(img)\n",
    "    img = img.unsqueeze(0)  #图片扩展多一维,因为输入到保存的模型中是4维的[batch_size,通道,长，宽]，而普通图片只有三维，[通道,长，宽]\n",
    "    print(img.shape)\n",
    "    \n",
    "    # 预测 \n",
    "    #output = model(img)\n",
    "    #predict = output.argmax(dim=1)\n",
    "    #print(predict.item())\n",
    "    \n",
    "    # 预测 \n",
    "    output = model(img)\n",
    "    predict = output.argmax(axis=1)\n",
    "    print(\"预测类别：\",predict.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义数据预处理方式\n",
    "def datapipe(path, batch_size):\n",
    "    image_transforms = [\n",
    "        #随机旋转图片\n",
    "        vision.RandomHorizontalFlip(),\n",
    "        #将图片尺寸resize到32x32\n",
    "        vision.Resize((32,32)),\n",
    "        #正则化(当模型出现过拟合的情况时，用来降低模型的复杂度)\n",
    "        vision.Normalize((0.1307,),(0.3081,)) ,\n",
    "        vision.HWC2CHW() \n",
    "    ]\n",
    "    label_transform = transforms.TypeCast(mindspore.int32)\n",
    "\n",
    "    dataset = MnistDataset(path)\n",
    "    dataset = dataset.map(image_transforms, 'image')\n",
    "    dataset = dataset.map(label_transform, 'label')\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下载数据集 \n",
    "    \n",
    "    url = \"https://mindspore-website.obs.cn-north-4.myhuaweicloud.com/\" \\\n",
    "        \"notebook/datasets/MNIST_Data.zip\"\n",
    "    path = download(url, \"./\", kind=\"zip\", replace=True)\n",
    "    #加载数据集\n",
    "    train_dataset = datapipe('MNIST_Data/train', batch_size=64)\n",
    "    test_dataset = datapipe('MNIST_Data/test', batch_size=64)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义模型与优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建模型，设置运行设备CPU，并设置图模式为动态图模式方便调试\n",
    "    mindspore.set_context(device_target='CPU',mode=mindspore.PYNATIVE_MODE)\n",
    "    model = LeNet()\n",
    "    #定义优化器\n",
    "    optimizer = nn.Adam(model.trainable_params(), learning_rate=0.001)\n",
    "    #计算损失和\n",
    "    #多分类情况通常使用cross_entropy(交叉熵损失函数), 而对于二分类问题, 通常使用sigmod\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    #定义前向函数\n",
    "    def forward_fn(data, label):\n",
    "        logits = model(data)\n",
    "        loss = loss_fn(logits, label)\n",
    "        return loss, logits\n",
    "    #根据前向函数定义梯度函数,对网络参数求导\n",
    "    grad_fn=mindspore.value_and_grad(forward_fn,None,optimizer.parameters,has_aux=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型训练并计算loss和accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#调用\n",
    "    epoch = 5\n",
    "    Loss = []\n",
    "    Accuracy = []\n",
    "    #设置为训练模式\n",
    "    model.set_train()\n",
    "    for epoch in range(1, epoch+1):\n",
    "        print(\"start_time\",time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())))\n",
    "        loss, acc = train_runner(grad_fn,  train_dataset, optimizer, epoch)\n",
    "        Loss.append(loss)\n",
    "        Accuracy.append(acc)\n",
    "        test_runner(model, test_dataset)\n",
    "        print(\"end_time: \",time.strftime('%Y-%m-%d %H:%M:%S',time.localtime(time.time())),'\\n')\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ckpt_dir='./models'\n",
    "    if not os.path.exists(best_ckpt_dir):\n",
    "        os.mkdir(best_ckpt_dir)\n",
    "    mindspore.save_checkpoint(model, './models/mnist.ckpt') #保存模型  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model('./models/mnist.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
